---
title: "Bayesian Data Inference"
author: "Natalie Rozak"
date: "6/19/2020"
output: 
  github_document:
    pandoc_args: --webtex=https://ibm.codecogs.com/png.latex?
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
 
``` {r global imports,warning=FALSE, message=FALSE}
# global imports
# data preprocessing
library(tidyverse)
library(reshape2)
library(caret)
# data visualization
library(kableExtra)
library(ggplot2)
library(gridExtra)
# models
library(rstan)
library(mvtnorm)
library(coda)
library(ROCR)

# supress scientific notation
options(scipen=999)
```

# Data Preprocessing

The dataset I used came from https://www.kaggle.com/laotse/credit-risk-dataset. This dataset is about loan defaults.

```{r import data}
# import data
data <- read.csv(
  '~/Documents/GitHub/R_LoanDefaultBayesianAnalysis/credit_risk_dataset.csv')
```

## Properties of Dataset

```{r output the structure of the data}
# output structure of the data
str(data)
```

## Remove Missing Values

```{r output number of missing values in each column,strip.white=TRUE}
# output number of missing values in each column
kable(t(sapply(data,function(x) sum(is.na(x))))) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), 
                full_width=TRUE,position='center')
```

```{r remove missing values}
# remove missing values
data <- data %>% na.omit()
```

## Remove Duplicates

```{r output number of duplicates}
# output number of duplicates
dim(data[duplicated(data),])
```

```{r remove duplicates}
# remove duplicates
data <- data[!duplicated(data),]
```

## Select Rows and Preliminary Columns for Analysis

```{r subset data frame}
# remove most categorical variables to make hierarhcical model simploer
data <- data %>% subset(select = -c(loan_grade,cb_person_default_on_file))
# obtain rows corresponding to medical
data <- data %>% filter(loan_intent=='MEDICAL')
# remove rows corresponding to `other`
data <- data %>% filter(person_home_ownership != 'OTHER')
# correct factor levels
data$person_home_ownership <- factor(data$person_home_ownership)
# remove variable
data <- data %>% subset(select=-c(loan_intent))
```

## Split Data into Prior, Observed, and Test

```{r split data into Prior, Observed, and Test}
# obtain observed size
n_observed <- floor(0.5*nrow(data))
# obtain prior indices
set.seed(897)
observed_ind <- sample(seq_len(nrow(data)),size=n_observed)
# obtain prior dataset
observed <- data[observed_ind,]
other <- data[-observed_ind,]
# obtain prior size
n_prior <- floor(0.5*nrow(other))
# obtain prior indicies
set.seed(981)
prior_ind <- sample(seq_len(nrow(other)),size=n_prior)
# obtain prior and test datasets
prior <- other[prior_ind,]
test <- other[-prior_ind,]
```

## Variable Selection

```{r function for statistically significant}
# function for stating whether a hypothesis test is statistically significant
statistically_significant <- function(pvalue){
  if (pvalue < 0.05){
    cat('Statistically significant\n')
  } else {
    cat('Not statistically significant\n')
  }
}
```

### Chi-Squared Test for Categorical Predictors

The null hypothesis for the chi-squared test is that home ownership type and loan status are independent. These variables are not independed in the alternative hypothesis for the chi-squared test. 

The test statistic is $\chi^2 = \sum_{i=1}^3\sum_{j=1}^2\frac{(x_{ij}-e_{ij})^2}{e_{ij}}$ where $e_{ij}=\frac{r_ic_j}{n}$, and there are two degrees of freedom for this contingency table. Under the null hypothesis, $\chi^2 \sim \chi^2_{(2)(1)}$.

```{r output levels in person_home_ownership for observed}
# outout levels in person_home_ownership
kable(table(observed$person_home_ownership,observed$loan_status),
      col.names=c('No Default','Default'))%>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), 
                full_width=FALSE,position='center')
```

```{r homeowner test}
# chi-squared test for person_home_ownership
homeowner_chisq <- table(observed$person_home_ownership,observed$loan_status)
homeowner_test <- chisq.test(homeowner_chisq)
# output results
statistically_significant(homeowner_test$p.value)
```

Since my p-value is less than alpha=0.05, I have statistically significant evidence to reject my null hypothesis. Homeowner type and loan status are not independent, so I will use this variable in the logistic regression model. 

### Mann-Whitney U Test for Continuous Predictors

***Visualize Variables***

```{r function for violin plot}
# function for creating a violin plot
violin_plot <- function(x,y,lab){
  ggplot() +
    geom_violin(aes_string(x=x,y=y,color=x,fill=x),show.legend=FALSE) +
    labs(title='Violin Plot') + ylab(lab) + xlab('Loan Default') + 
    scale_color_manual(name='Legend',
                       values=c('0'='deepskyblue2',
                                '1'='darkorange2'),
                       labels=c('No Default','Default'))+
    scale_fill_manual(name='Legend',
                       values=c('0'='deepskyblue2',
                                '1'='darkorange2'),
                       labels=c('No Default','Default'))+
    theme(plot.title=element_text(face='bold'))
}
```

```{r violin plots,fig.align='center',fig.width=8,fig.height=8}
# lists used in for loop
num_cols <- c('person_age','person_income','person_emp_length','loan_amnt',
              'loan_int_rate','loan_percent_income','cb_person_cred_hist_length')
y_name <- c('Age','Income','Length of Employment','Loan Amount','Interest Rate',
            'Loan Percent of Income','Credit History Length')
plots <- list()
# create violin plot for each variable
for (i in 1:length(num_cols)){
  plots[[i]] <-violin_plot(factor(observed$loan_status),observed[[num_cols[i]]],y_name[i])
}
# plot grid
do.call(grid.arrange,c(plots,ncol=3))
```

The violin plots show that age, income, length of employment, and credit history have fairly similar distributions.

***Run Hypothesis Test***

The null hypothesis for the Mann-Whitney U test is that the ranks are uniformly distributed and the distributions of default and no default values are identical. The alternative hypothesis is that these distributions are not identical. 

The Mann-Whitney test statistic is $U=W-\frac{m(m+1)}{2}$ where $W$ is the sum of the ranks from sample $X$ and $m$ is the number of observations in $X$.

```{r age test}
# Mann Whitney U test for age
age_test <- wilcox.test(observed$person_age~observed$loan_status)
# output results
statistically_significant(age_test$p.value)
```

Since my p-value is greater than alpha=0.05, I do not have statistically significant evidence to reject my null hypothesis. Loan status is not impacted by the age of the person.

```{r income test}
# Mann Whitney U test for income
income_test <- wilcox.test(observed$person_income~observed$loan_status)
# output results
statistically_significant(income_test$p.value)
```

Since my p-value is less than alpha=0.05, I have statistically significant evidence to reject my null hypothesis. Loan status is impacted by the income of the person.

```{r employment test}
# Mann Whitney U test for employment length
employment_test <- wilcox.test(observed$person_emp_length~observed$loan_status)
# output results
statistically_significant(employment_test$p.value)
```

Since my p-value is greater than alpha=0.05, I do not have statistically significant evidence to reject my null hypothesis. Loan status is not impacted by amount of time that a person was employed.

```{r amount test}
# Mann Whitney U test for loan amount
amount_test <- wilcox.test(observed$loan_amnt~observed$loan_status)
# output results
statistically_significant(amount_test$p.value)
```

Since my p-value is less than alpha=0.05, I have statistically significant evidence to reject my null hypothesis. Loan status is impacted by the loan amount.

```{r interest test}
# Mann Whitney U test for interest
interest_test <- wilcox.test(observed$loan_int_rate~observed$loan_status)
# output results
statistically_significant(interest_test$p.value)
```

Since my p-value is less than alpha=0.05, I have statistically significant evidence to reject my null hypothesis. Loan status is impacted by the loan interest rate.

```{r percent income test}
# Mann Whitney U test for percent income
percent_income_test <- wilcox.test(observed$loan_percent_income~observed$loan_status)
# output results
statistically_significant(percent_income_test$p.value)
```

Since my p-value is less than alpha=0.05, I have statistically significant evidence to reject my null hypothesis. Loan status is impacted by the percentage of a person's income that a loan equates to.

```{r credit history test}
# Mann Whitney U test for credit history
credit_history_test <- wilcox.test(
  observed$cb_person_cred_hist_length~observed$loan_status)
# output results
statistically_significant(credit_history_test$p.value)
```

Since my p-value is greater than alpha=0.05, I do not have statistically significant evidence to reject my null hypothesis. Loan status is not impacted by the credit history of the person.

```{r select predictors for each data frame}
# remove columns that are not statistically significant predictors
prior <- prior %>%
  subset(select=-c(person_age,person_emp_length,cb_person_cred_hist_length))
observed <- observed %>%
  subset(select=-c(person_age,person_emp_length,cb_person_cred_hist_length))
test <- test %>% 
  subset(select=-c(person_age,person_emp_length,cb_person_cred_hist_length))
```

# Exploration of `loan_status` Variable

## Levels of `loan_status`

***Prior Dataset***

```{r output levels in target for prior}
# outout levels in target
kable(table(prior$loan_status), col.names=c('Level','Count')) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), 
                full_width=FALSE,position='center')
```

***Observed Dataset***

```{r output levels in target for observed}
# outout levels in target
kable(table(observed$loan_status), col.names=c('Level','Count')) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), 
                full_width=FALSE,position='center')
```

## Beta-Binomial Model for `loan_status`

```{r create functions}
# x values for functions
x <- seq(0.21,0.32,length=1000)
# function for plotting bayes model
bayes_model_plot <- function(model){
  ggplot(model) + 
    geom_line(aes(x=x,y=Density,color=Model)) +
    labs(title='Bayesian Model') + ylab('Density') +
    scale_color_manual(name='Models',
                       values=c('Prior'='deepskyblue2',
                                'Observed'='darkorange2',
                                'Posterior'='maroon3'),
                       labels=c('Prior','Observed','Posterior')) +
    theme(plot.title=element_text(face='bold'))
}
```

```{r sampling distribution}
# obtain parameters
n <- nrow(observed)
y <- sum(observed$loan_status)
# create parameters for sampling distribution
observed_dist <- dbeta(x,y+1,n-y+1)
```

Since the beta pdf and binomial pdf are proportional, I decided to use the beta pdf to describe the observed distribution. Doing this makes the graph more readable. 

### Model Building

Apriori, $\theta\sim Beta(334,980)$ with $P(\theta)\propto \theta^{333}(1-\theta)^{980}$. Observe $Y|\theta\sim Bin(2627,0.2763)$ with $P(Y|\theta)\propto \theta^{726}(1-\theta)^{1901}$. Then the posterior distribution is $\theta|726\sim Beta(1060,2881)$ with $P(\theta|726)\propto \theta^{1059}(1-\theta)^{2880}$.

```{r conjugate graph,warning=FALSE,message=FALSE,fig.align='center',fig.width=6.5,fig.height=3.5}
# obtain parameters
alpha <- sum(prior$loan_status)
beta <- nrow(prior)-alpha
a_post <- alpha+y
b_post <- beta+n-y
# create the prior and posterior distributions
prior_dist <- dbeta(x,alpha,beta)
posterior_dist <- dbeta(x,a_post,b_post)
# create model name vectors
prior_name <- rep('Prior',length(x))
observed_name <- rep('Observed',length(x))
posterior_name <- rep('Posterior',length(x))
# create data frames
prior_df <- data.frame(prior_name,prior_dist,x)
prior_df <- prior_df %>% plyr::rename(c('prior_name'='Model','prior_dist'='Density'))
observed_df <- data.frame(observed_name,observed_dist,x)
observed_df <- observed_df %>%
  plyr::rename(c('observed_name'='Model','observed_dist'='Density','x'))
posterior_df <- data.frame(posterior_name,posterior_dist,x)
posterior_df <- posterior_df %>%
  plyr::rename(c('posterior_name'='Model','posterior_dist'='Density'))
conjugate <- rbind(prior_df,observed_df,posterior_df)
# create graph
bayes_model_plot(conjugate)
```

### Posterior Mean 

$E(\theta|726)=w\hat{\theta}_{MLE}+(1-w)\hat{\theta}_{prior\:mean}=\frac{2627}{3941}\frac{726}{2627}+\frac{1314}{3941}\frac{334}{1314}=0.2689$.

### Bias and Variance

The bias of the model is $E(w\bar{Y}+(1-w)\theta_0-\theta)=(1-w)(\theta_0-\theta)=0.3334(0.2541-\theta)$. The variance of the model is $Var(w\bar{Y}+(1-w)\theta_0)=w^2Var(\bar{Y})=0.1111Var(\bar{Y})$. The bias increases and the variance decreases when using the Bayesian estimate instead of the maximum likelihood estimate.

### Posterior Predictive Distribution

The posterior predictive distribution is a Beta-Binomial model with probability density $P(\tilde{y}|y)=\frac{\Gamma(n+1)}{\Gamma(\tilde{y}+1)\Gamma(n-\tilde{y}+1)}\frac{\Gamma(3941)}{\Gamma(1060)\Gamma(2881)}\frac{\Gamma(\tilde{y}+1060)\Gamma(n-\tilde{y}+2881)}{\Gamma(n+3941)}$.

### Monte Carlo Simulation

Run a Monte Carlo simulation with test statistic $t = E(y^{(s)})$ from sampling model with $\theta^{(s)}$ as a parameter.

```{r monte carlo simulation functions}
# monte carlo simulation function
monte_carlo <- function(size){
  T_ytilde <- c()
  for (s in 1:1000){
    # obtain theta_s from posterior distribution
    theta_s <- rbeta(1,a_post,b_post)
    # obtain 10 y values from sampling model with parameter theta_s
    y_s <- rbinom(10,size,theta_s)
    # calculate the test statistic
    t_s <- mean(y_s)
    T_ytilde <- c(T_ytilde,t_s)
  }
  return(T_ytilde)
}
# monte carlo simulation graphs
monte_carlo_plot <- function(test_stat, real){
  ggplot() +
    geom_histogram(aes(x=test_stat,y=..density..),bins=20,alpha=0.5,fill='deepskyblue2') +
    geom_density(aes(x=test_stat),alpha=0.3,color='deepskyblue2',fill='deepskyblue2') + 
    geom_segment(
      aes(x=real,y=0,xend=real,yend=Inf),color='darkorange2',linetype='dashed') +
    labs(title='Monte Carlo Simulation') + 
    xlab('Number of Defaults') + ylab('Density') +
    theme(plot.title=element_text(face='bold'))
}
```

***Observed Data***

```{r monte carlo on observed data, fig.align='center', fig.width=5, fig.height=3.5}
# obtain test statistic for observed and simulated data
T_yobs <- sum(observed$loan_status)
T_ytilde <- monte_carlo(n)
# create plot
monte_carlo_plot(T_ytilde,T_yobs)
```

The observed number of defaults lies on the histogram for the Monte Carlo simulated number of defaults.

***Test Data***

```{r monte carlo on test data, fig.align='center', fig.width=5, fig.height=3.5}
# obtain test statistic for observed and simulated data
T_ytest <- sum(test$loan_status)
T_ytilde <- monte_carlo(nrow(test))
# create plot
monte_carlo_plot(T_ytilde,T_ytest)
```

The test number of defaults lies on the histogram for the Monte Carlo simulated number of defaults.

### Posterior Credible Interval

```{r function for plotting credible interval}
# function for plotting the credible interval
cred_int_plot <- function(model,lower,upper){
  ggplot() +
    geom_line(aes(x,model),color='deepskyblue2') +
    geom_area(mapping=aes(x=ifelse(x>lower & x<upper,x,0),y=model),
      fill='deepskyblue2', alpha=0.3) + 
    xlim(0.23,0.31) +
    labs(title='Credible Interval') + 
    xlab('Theta') + ylab('Density') +
    theme(plot.title=element_text(face='bold'))
}
```

```{r posterior credible interval}
# MLE for observed data
p <- sum(observed$loan_status)/nrow(observed)
# obtain bounds
bounds <- qbeta(c(0.025,0.975),a_post,b_post)
# print bounds
cat('Lower bound: ',bounds[1],'\n')
cat('Upper bound: ',bounds[2],'\n')
```

There is a 95% chance that $\theta$ lies between 0.2552 and 0.2829.

```{r plot credbile interval,warning=FALSE,fig.align='center',fig.width=5,fig.height=3.5}
# plot credible interval with MLE from observed data
cred_int_plot(posterior_dist,bounds[1],bounds[2]) + 
  geom_segment(aes(x=p,y=0,xend=p,yend=Inf),color='darkorange2',linetype='dashed')
```

The maximum likelihood estimate from the observed data lies in the credible interval for $\theta$.

## Hierarchical Model for `loan_status`

```{r data for hierarchical model}
# observed data
h_model_obs <- observed %>% 
  group_by(person_home_ownership) %>% 
  summarise(y=sum(loan_status),n=n())
# test data
h_test <- test %>% 
  group_by(person_home_ownership) %>% 
  summarise(y=sum(loan_status),n=n()) %>%
  mutate(percent=y/n)
# add test data to h_model
h_model_obs$test <- h_test$percent
# obtain values
y <- h_model_obs$y
n <- h_model_obs$n
J <- nrow(h_model_obs)
```

### No Pooling

The no pooling estimate for the parameter of each group is $\hat{\theta}_i^{(mle)}=yi$.

```{r no pooling estimate}
# no pooling estimate
no_pool <- y/n
# output the no pooling estimate for each group
for (i in 1:length(h_model_obs$person_home_ownership)){
  cat('No pooling estimate for ',
      as.vector(h_model_obs$person_home_ownership)[i],' : ',no_pool[i],'\n')
}
```

### Complete Pooling

The complete pooling estimate for the parameter of each group is $\hat{\theta}_i^{(pool)}=\frac{\sum_jy_j}{\sum_jn_j}$.

```{r complete pooling estimate}
# complete pooling estimate
complete_pool <- sum(y)/sum(n)
# output the complete pooling estimate
cat('Complete pooling estimate: ',complete_pool)
```

### Shrinkage Model 

The shrinkage estimate for the parameter of each group is $\hat{\theta}_i^{(shrink)}=w\hat{\theta}_i^{(mle)}+(1-w)\hat{\theta}_i^{(pool)}$. 

The sampling model is $Y_i\sim Bin(n_i,\theta_i)$. The parameter for each group is $\theta_i \sim Beta(\alpha,\beta)$. Lastly, $\alpha,\beta\sim P(\alpha,\beta)$. The full model is $P(y,\theta,\alpha,\beta)=\prod_{i=1}^N{n_i \choose y_i}\theta_i^{y_i}(1-\theta_i)^{n_i-y_i}\prod_{i=1}^N\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta_i^{\alpha-1}(1-\theta_i)^{\beta-1}P(\alpha,\beta)$.

#### Prior Data

```{r functions for bootstrapping}
# function for counting number of positive in a bootstrap sample
bootstrap <- function(vector,num_samp){
  num_pos <- c()
  for (i in 1:num_samp){
    set.seed(187+i)
    samp <- sample(vector,nrow(prior),replace=TRUE)
    num_pos <- c(num_pos,sum(samp))
  }
  return(num_pos)
}
# function for plotting bootstrapped sample
bootstrap_plot <- function(samples, mu){
  ggplot() +
    geom_histogram(aes(x=samples,y=..density..),bins=20,alpha=0.5,fill='deepskyblue2') +
    geom_density(aes(x=samples),alpha=0.3,color='deepskyblue2',fill='deepskyblue2') + 
    geom_segment(aes(x=mu,y=0,xend=mu,yend=Inf),color='darkorange2',linetype='dashed') +
    labs(title='Bootstrap Sample') + 
    xlab('Number of Observations') + ylab('Density') +
    theme(plot.title=element_text(face='bold'))
}
```

```{r determine prior sample size distribution}
# obtain samples of sample size
pos_samples <- bootstrap(prior$loan_status,1000)
p <- sum(prior$loan_status)/nrow(prior)
samples <- pos_samples/p
# output mean and standard deviation
cat("Mean of samples: ",mean(samples),'\n')
cat("Standard deviation of samples: ",sd(samples),'\n')
```
```{r histogram of prior distribution, fig.align='center',fig.width=5,fig.height=3.5}
# plot bootstrap samples
bootstrap_plot(samples,mean(samples))
```

To determine the prior distribution for $\alpha$ and $\beta$, I considered $\mu=\frac{\alpha}{\alpha+\beta}\sim Beta(860,2293)$. Next, I created a distribution for the prior sample size $\eta \sim N(\mu_0,\sigma_0)$. Then $\alpha=\eta\times \mu$ and $\beta=\eta\times(1-\mu)$.

#### Model Building

```{r prior data stan model}
# apriori parameters
m <- mean(samples)
std <- sd(samples)
# attach stan file
h_model <- stan_model('~/Documents/MachineLearning/Bayes/loan_status.stan')
# fit posterior distribution
set.seed(987)
stan_fit <- rstan::sampling(
  h_model, data=list(J=J,y=y,n=n,a=alpha,b=beta,m=m,std=std),refresh=0)
# samples from posterior distribution
h_model_samples <- rstan::extract(stan_fit)
```
```{r prior data shrinkgave}
# obtain values
shrinkage <- colMeans(h_model_samples$theta)
# output shrinkage estimate for each group
for (i in 1:length(h_model_obs$person_home_ownership)){
  cat('Prior data shrinkage estimate for ',
      as.vector(h_model_obs$person_home_ownership)[i],
      ' : ',shrinkage[i],'\n')
}
```

#### Results

```{r theta histogram,warning=FALSE,message=FALSE,fig.align='center',fig.width=6.5,fig.height=3.5}
# obtain data frame
thetas_df <- data.frame(h_model_samples$theta)
thetas_df <- reshape2::melt(thetas_df)
# create histogram
ggplot(thetas_df,aes(x=value,fill=variable)) +
  geom_histogram(aes(y=..density..),bins=20,alpha=0.5,position='identity') +
  geom_density(aes(color=variable),alpha=0.3) +
  scale_color_manual(name='Theta',
                       values=c('X1'='deepskyblue2',
                                'X2'='darkorange2',
                                'X3'='maroon3'),
                       labels=c('Mortgage','Own','Rent')) +
  scale_fill_manual(name='Theta',
                       values=c('X1'='deepskyblue2',
                                'X2'='darkorange2',
                                'X3'='maroon3'),
                       labels=c('Mortgage','Own','Rent')) +
  labs(title='Histogram of Hierarchical Thetas') + 
  xlab('Theta') + ylab('Density') +
  theme(plot.title=element_text(face='bold'))
```

```{r shrinkage plot,warning=FALSE,fig.align='center',fig.width=7.5,fig.height=3.5}
# shrinkage plot
ggplot() +
  geom_segment(aes(x=no_pool,xend=shrinkage,y=1,yend=0,
                   color='Shrinkage Estimates')) +
  geom_point(aes(x=no_pool,y=1),color='deepskyblue2') + 
  geom_point(aes(x=shrinkage,y=0),color='deepskyblue2') +
  geom_segment(aes(x=mean(shrinkage),xend=mean(shrinkage),y=0,yend=1,
                   color='Shrinkage Mean')) + 
  geom_point(aes(x=mean(shrinkage),y=1),color='darkorange2') + 
  geom_point(aes(x=mean(shrinkage),y=0),color='darkorange2') +
  geom_segment(aes(x=complete_pool,xend=complete_pool,y=0,yend=1,
                   color='Complete Pooling Mean')) +
  geom_point(aes(x=complete_pool,y=1),color='maroon3') + 
  geom_point(aes(x=complete_pool,y=0),color='maroon3') +
  labs(title='Shrinkage Plot') + 
  xlab('Theta') + ylab('') +
  scale_y_continuous(breaks=c(0, 1),labels=c("Bayes", "MLE"),limits=c(0,1)) +
  scale_color_manual(name='Legend',values=c('Shrinkage Estimates'='deepskyblue2',
                                            'Shrinkage Mean'='darkorange2',
                                            'Complete Pooling Mean'='maroon3')) +
  theme(plot.title=element_text(face='bold'))
```

The shrinkage estimates are much closer to the shrinkage mean and complete pooling mean than they are to the MLE.

### Compare Models

```{r rmse function}
# rmse function
rmse <- function(y,y_hat){
  return(sqrt(mean((y-y_hat)^2)))
}
```

```{r output results}
# output results
cat('No pooling RMSE: ',rmse(h_model_obs$test,no_pool),'\n')
cat('Complete pooling RMSE: ',rmse(h_model_obs$test,complete_pool),'\n')
cat('Shrinkage RMSE',rmse(h_model_obs$test,colMeans(h_model_samples$theta)),'\n')
```

The no pooling estimate has the lowest RMSE, meaning it is the best model. Therefore, differences in home ownership status significantly impact the probability of a loan defaulting. It seems likely that the loan default parameter comes from a different distribution for each home ownership status level.

# Bayesian Logistic Regression

Apriori, assume $\boldsymbol{\beta} \propto C$. The sampling model is $Y_i\sim Bin(n,\theta)$ where $\theta=\frac{e^{\boldsymbol{\beta X}}}{1+ e^{\boldsymbol{\beta X}}}$. The posterior distribution is $P(\theta|y)= L(\theta)P(\theta) \propto \prod_{i=1}^n \Big(\ \frac{e^{\boldsymbol{\beta X}}}{1+ e^{\boldsymbol{\beta X}}}\Big)^{y_i}\Big(1-\frac{e^{\boldsymbol{\beta X}}}{1+ e^{\boldsymbol{\beta X}}}\Big)^{1-y_i}$. 

```{r create train}
# create train
train <- observed
# one hot encode person_home_ownership
train$mortgage <- ifelse(as.character(train$person_home_ownership)=='MORTGAGE',1,0)
train$own <- ifelse(as.character(train$person_home_ownership)=='RENT',1,0)
train <- train %>% subset(select=-c(person_home_ownership))
# create predictor and response
train_X <- train %>% subset(select=-c(loan_status))
train_y <- train$loan_status
# scale train_X
norm_pars <- preProcess(train_X)
train_X <- predict(norm_pars,train_X)
```
```{r create test}
# create test
test_logistic <- test
# one hot encode person_home_ownership
test_logistic$mortgage <- 
  ifelse(as.character(test_logistic$person_home_ownership)=='MORTGAGE',1,0)
test_logistic$own <- 
  ifelse(as.character(test_logistic$person_home_ownership)=='RENT',1,0)
test_logistic <- test_logistic %>% subset(select=-c(person_home_ownership))
# create predictor and response
test_logistic_X <- test_logistic %>% subset(select=-c(loan_status))
test_logistic_y <- test_logistic$loan_status
# scale train_X
test_logistic_X <- predict(norm_pars,test_logistic_X)
```
```{r functions for logistic regression}
# function for making predictions
logistic_predictions <- function(X,betas){
  X_new <- X
  X_new$ones <- rep(1,nrow(X_new))
  sums <- colSums(t(X_new)*betas)
  predictions <- c()
  for (i in 1:length(sums)){
    predictions <- c(predictions, exp(sums[i])/(1+exp(sums[i])))
  }
  return(predictions)
}
# function for plotting predictions 
pred_plot <- function(pred,observe){
  ggplot() +
    geom_histogram(aes(x=prob,fill=observe,y=..density..),
                   bins=20,alpha=0.5,position='identity') +
    geom_density(aes(x=prob,fill=observe,color=observe),alpha=0.3) +
    scale_color_manual(name='Observed',
                       values=c('0'='deepskyblue2',
                                '1'='darkorange2'),
                       labels=c('No Default','Default')) +
    scale_fill_manual(name='Observed',
                      values=c('0'='deepskyblue2',
                               '1'='darkorange2'),
                      labels=c('No Default','Default')) +
    labs(title='Logistic Regression Probabilities') + 
    xlab('Probability') + ylab('Density') +
    theme(plot.title=element_text(face='bold'))
}
# function for plotting pr curve
pr_curve <- function(recall,precision){
  ggplot() +
    geom_line(aes(recall,precision),color='deepskyblue2') +
  labs(title='Precision-Recall Curve') + 
  xlab('Recall') + ylab('Precision') +
  theme(plot.title=element_text(face='bold'))
}
# function for finding cut off
find_cut_off <- function(precision, cutoff, recall){
  rate <- as.data.frame(cbind(Cutoff=cutoff,Precision=precision,Recall=recall))
  rate$distance <- sqrt((rate[,2]^2)+(rate[,3]^2))
  index <- which.min(rate$distance)
  return(rate$Cutoff[index])
}
```

## Log Posterior

The log of the posterior distribution is $\ell(\theta|y)\propto \sum_{i=1}^nlog\Big[\Big(\ \frac{e^{\boldsymbol{\beta X}}}{1+ e^{\boldsymbol{\beta X}}}\Big)^{y_i}\Big(1-\frac{e^{\boldsymbol{\beta X}}}{1+ e^{\boldsymbol{\beta X}}}\Big)^{1-y_i}\Big]$.

```{r function for calculating the log of the posterior}
# function for calculating the log of the posterior
log_posterior <- function(beta){
  probs <- c()
  for (i in 1:nrow(train_X)){
    power <- beta[1]+(beta[2]*train_X[i,1])+(beta[3]*train_X[i,2])+
      (beta[4]*train_X[i,3])+(beta[5]*train_X[i,4])+(beta[6]*train_X[i,5])+
      (beta[7]*train_X[i,6])
    probs <- c(probs,exp(power)/(1+exp(power)))
  }
  if (any(probs==0)|any(probs==1)){
    return(-Inf)
  } else{
    total <- 0
    for (i in 1:length(probs)){
      total <- total + log((probs[i]^train_y[i])*((1-probs[i])^(1-train_y[i])))
    }
    return(total)
  }
}
```

## Metropolis Hastings Algorithm

Here are the steps for using the Metropolis Hastings Algorithm to find $\Beta$ values for Bayesian Logistic Regression:

1. Start a Markov Chain at $\theta_0$
2. Generate $\theta^*$ from the proposal distribution $J(\theta^*|\theta_t)\sim N(\theta_t,\Sigma)$
3. Compute $r=min(0,log(P(\theta^*|y))-log(P(\theta_t|y)))$
4. Generate a uniform random number $u$ from $U\sim Unif(0,1)$
5. Set $\theta_{t+1}\leftarrow\theta^*$ with probability $r$
  + If $log(u)<log(r)$, accept $\theta^*$ as the next sample, meaning $\theta_{t+1}=\theta*$
  + Otherwise keep $\theta$ at its current value: $\theta_{t+1}=\theta_t$
  
```{r function for metropolis hastings algorithm}
# r logistic regression
logistic_regression <- function(beta_0,burnin,iter,sigma){
  betas <- NULL
  beta_t <- beta_0
  for (i in 1:iter){
    set.seed(143+i)
    beta_p <- mvtnorm::rmvnorm(1,mean=beta_t,sigma=sigma)
    log_r <- min(0,log_posterior(beta_p)-log_posterior(beta_t))
    u <- runif(1,min=0,max=1)
    if(log(u)<log_r){
      beta_t <- beta_p
    }
    betas <- rbind(betas,beta_t)
  }
  if (burnin!=0)
    betas <- betas %>% tail(-1*burnin)
  return(betas)
}
```

```{ function for finding best variance, very long to run}
# function for finding best variance
find_var <- function(vars,beta_0){
  results <- NULL
  for (i in vars){
    model <- logistic_regression(beta_0,750,2000,i*diag(7))
    total <- 0 
    for (j in 1:7){
      total <- total+effectiveSize(model[,j])
    }
    results <- rbind(results,c(i,total))
  }
  return(results)
}
# find best variance
beta_0 <- rep(0,7)
vars <- find_var(c(0.005,0.006,0.007,0.009),beta_0)
```

```{r train logistic regression model}
# train logistic regression model
beta_0 <- rep(0,7)
mh_logistic <- logistic_regression(beta_0,750,2000,0.005*diag(7))
# output effective sample size for each beta
for (i in 1:7){
  cat('Effective size for beta',i,' :',effectiveSize(mh_logistic[,i]),'\n')
}
```

The effective size for $\beta_6$ and $\beta_7$ are fairly small. 

```{r traceplot of each mh beta,fig.align='center',fig.width=8,fig.height=8}
# create trace plots
par(mfcol=c(3,3))
for (i in 1:7){
  coda::traceplot(as.mcmc(mh_logistic[,i]),col='deepskyblue2',
                  main=paste('Traceplot for Beta',i))
}
```

The traceplots for $\beta_6$ and $\beta_7$ show high autocorrelation, meaning that a larger variance for these $\beta$s would increase the number of samples. 

```{r plot of each mh beta,fig.align='center',fig.width=8,fig.height=8}
# create density plots
par(mfcol=c(3,3))
for (i in 1:7){
  densplot(as.mcmc(mh_logistic[,i]),col='deepskyblue2',
       main=paste('Density Plot for Beta',i))
}
```

The density plot for each $\beta$ is roughly normal.

```{r output each mh beta}
# output betas for logistic regression model
for (i in 1:7){
  cat('beta',i,' :',mean(mh_logistic[,i]),'\n')
}
```

```{r obtain mh predictions,fig.align='center',fig.width=6.5,fig.height=3.5}
# create betas
mh_betas <- c()
for (i in 1:7) {
  mh_betas <- c(mh_betas,mean(mh_logistic[,i]))
}
# create data frame
prob <- logistic_predictions(train_X,mh_betas)
mh_pred_train <- data.frame(prob)
mh_pred_train$observe <- as.factor(train_y)
# plot predictions
pred_plot(mh_pred_train$prob,mh_pred_train$observe)
```

Observations with probabilities around 90% are likely to default.

```{r mh precision and recall curve,warning=FALSE,message=FALSE,fig.align='center', fig.width=5,fig.height=3.5}
# obtain precision and recall
mh_predict <- prediction(mh_pred_train$prob,mh_pred_train$observe)
mh_performance <- performance(mh_predict,'prec','rec')
# plot area under pr curve
pr_curve(performance(mh_predict, 'rec')@y.values[[1]],
         performance(mh_predict, 'prec')@y.values[[1]])
```

```{r find mh cut off}
# find cut off
mh_best <- find_cut_off(performance(mh_predict, 'prec')@y.values[[1]],
                        performance(mh_predict, 'prec')@x.values[[1]],
                        performance(mh_predict, 'rec')@y.values[[1]])
# output the result
cat('Cutoff: ',mh_best)
```

```{r mh train}
# use threshold to classify observations
mh_pred_train$pred <- ifelse(mh_pred_train$prob>=mh_best,'1','0')
# create confusion matrix
kable(table(pred=mh_pred_train$pred,true=mh_pred_train$observe),
      col.names=c('No Default','Default'))%>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), 
                full_width=FALSE,position='center')
```

```{r mh test}
# create data frame
prob <- logistic_predictions(test_logistic_X,mh_betas)
mh_pred_test <- data.frame(prob)
mh_pred_test$observe <- as.factor(test_logistic_y)
# make predictions
mh_pred_test$pred <- ifelse(mh_pred_test$prob>=mh_best,'1','0')
# create confusion matrix
kable(table(pred=mh_pred_test$pred,true=mh_pred_test$observe),
      col.names=c('No Default','Default'))%>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), 
                full_width=FALSE,position='center')
```

The model has a 70.01% accuracy on the test set. It misclassifies default observations more often than no default observations. This is because the dataset is unbalanced and the model has not adequately learned the trends in the defaulted observations.

## Hamiltonian Monte Carlo

HMC is a method for producing proposals that are accepted with high probability by using Hamiltonian dynamics instead of a proposal distribution. I also used this method to create a logistic regression model.

```{r fit logistic regression stan model}
# logistic regression stan model
logistic_model <- stan_model('logistic_regression.stan')
# fit posterior distribution
set.seed(136)
stan_fit <- rstan::sampling(
  logistic_model, data=
    list(N=nrow(train_X),y=train_y,sigma=10,K=6,X=train_X),refresh=0)
# samples from posterior distribution
logistic_model_samples <- rstan::extract(stan_fit)
```

```{r traceplot of each hmc beta,fig.align='center',fig.width=8,fig.height=8}
# create trace plots
par(mfcol=c(3,2))
for (i in 1:6){
  coda::traceplot(as.mcmc(logistic_model_samples$beta[,i]),col='deepskyblue2',
                  main=paste('Traceplot for Beta',i))
}
```

All traceplots show a low autocorrelation and a low rejection rate.

```{r plot of each hmc beta,fig.align='center',fig.width=8,fig.height=8}
# create density plots
par(mfcol=c(3,2))
for (i in 1:6){
  densplot(as.mcmc(logistic_model_samples$beta[,i]),col='deepskyblue2',
       main=paste('Density Plot for Beta',i))
}
```

All $\beta$s have observations following a roughly normal distribution.

```{r output each hmc beta}
# output betas for logistic regression model
cat('alpha:',mean(logistic_model_samples$alpha),'\n')
for (i in 1:6) {
  cat('beta',i,': ',mean(logistic_model_samples$beta[,i]),'\n')
}
```

```{r obtain hmc predictions,warning=FALSE,message=FALSE,fig.align='center', fig.width=5,fig.height=3.5}
hmc_betas <- c(mean(logistic_model_samples$alpha))
for (i in 1:6){
  hmc_betas <- c(hmc_betas,mean(logistic_model_samples$beta[,i]))
}
# create data frame
prob <- logistic_predictions(train_X,hmc_betas)
hmc_pred_train <- data.frame(prob)
hmc_pred_train$observe <- as.factor(train_y)
# plot predictions
pred_plot(hmc_pred_train$prob,hmc_pred_train$observe)
```

Observations with probabilities greater than 90% often default.

```{r hmc precision and recall curve,warning=FALSE,message=FALSE,fig.align='center', fig.width=5,fig.height=3.5}
# obtain precision and recall
hmc_predict <- prediction(hmc_pred_train$prob,hmc_pred_train$observe)
hmc_performance <- performance(hmc_predict,'prec','rec')
# plot area under pr curve
pr_curve(performance(hmc_predict, 'rec')@y.values[[1]],
         performance(hmc_predict, 'prec')@y.values[[1]])
```

```{r find hmc cut off}
# find cut off
hmc_best <- find_cut_off(performance(hmc_predict, 'prec')@y.values[[1]],
                         performance(hmc_predict, 'prec')@x.values[[1]],
                         performance(hmc_predict, 'rec')@y.values[[1]])
# output the result
cat('Cutoff: ',hmc_best)
```

```{r hmc train}
# use threshold to classify observations
hmc_pred_train$pred <- ifelse(hmc_pred_train$prob>=hmc_best,'1','0')
# create confusion matrix
kable(table(pred=hmc_pred_train$pred,true=hmc_pred_train$observe),
      col.names=c('No Default','Default'))%>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), 
                full_width=FALSE,position='center')
```

```{r hmc test}
# create data frame
prob <- logistic_predictions(test_logistic_X,hmc_betas)
hmc_pred_test <- data.frame(prob)
hmc_pred_test$observe <- as.factor(test_logistic_y)
# make predictions
hmc_pred_test$pred <- ifelse(hmc_pred_test$prob>=hmc_best,'1','0')
# create confusion matrix
kable(table(pred=hmc_pred_test$pred,true=hmc_pred_test$observe),
      col.names=c('No Default','Default'))%>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), 
                full_width=FALSE,position='center')
```

Similarly, since that dataset is imbalanced, the Hamiltonian Monte Carlo method misclassifies default more often than it misclassifies no default. The accuracy on the test set is 69.77%. 